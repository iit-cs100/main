{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS100: Introduction to the Profession\n",
    "** Ethics **\n",
    "\n",
    "*[Aron Culotta](http://cs.iit.edu/~culotta)*  \n",
    "*[Illinois Institute of Technology](http://iit.edu)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br>\n",
    "## Privacy and Ethics in CS\n",
    "\n",
    "<br><br><br><br><br><br><br>\n",
    "\n",
    "### Morals vs. Ethics?\n",
    "\n",
    "\n",
    "<br><br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "**morals** /ˈmôrəls/:\n",
    "> a person's standards of behavior or beliefs concerning what is and is not acceptable for them to do.   \n",
    "> synonyms:\tmoral code, code of ethics, (moral) values, principles, standards, (sense of) morality, scruples\n",
    "\"he has no morals\"  \n",
    "\n",
    ">  late Middle English: from Latin moralis, from mos, mor- ‘custom,’ (plural) mores ‘morals.’ As a noun the word was first used to translate Latin Moralia, the title of St. Gregory the Great's moral exposition of the Book of Job, and was subsequently applied to the works of various classical writers.\n",
    "<br><br><br><br><br><br><br>\n",
    "\n",
    "**eth·ics** /ˈeTHiks/:\n",
    "> moral principles that govern a person's behavior or the conducting of an activity.\n",
    "\n",
    "> late Middle English (denoting ethics or moral philosophy; also used attributively): from Old French éthique, from Latin ethice, from Greek ( hē) ēthikē (tekhnē ) ‘(the science of) morals,’ based on ēthos (see ethos).\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "<img src=\"images/omerta.jpeg\" width=50%/>\n",
    "\n",
    "![morals](images/morals.png)\n",
    "\n",
    "![ethics](images/ethics.png)\n",
    "<br><br><br><br><br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![harvard](images/harvard.png)\n",
    "[source](https://www.chronicle.com/article/Harvards-Privacy-Meltdown/128166)\n",
    "- A study to measure homophily in Facebook\n",
    "  - Do friends have similar tastes in books/music/etc.\n",
    "- Questions about data collection process\n",
    "- Easy to de-anonymize\n",
    "> ... a privacy scholar at the University of Wisconsin at Milwaukee, Michael Zimmer, showed that the \"anonymous\" data of Mr. Kaufman and his colleagues could be cracked to identify the source as Harvard undergraduates.\n",
    "\n",
    "<br><br><br><br><br><br>\n",
    "\n",
    "![fb](images/fb.png)\n",
    "[source](https://www.nytimes.com/2014/06/30/technology/facebook-tinkers-with-users-emotions-in-news-feed-experiment-stirring-outcry.html)\n",
    "- A study by Facebook to measure how your feed affects your mood\n",
    "  - Manipulated the feed of ~600k users by altering number of positive/negative posts the user sees\n",
    "  - Measured the positive/negative posts the user then wrote\n",
    "> Although academic protocols generally call for getting people’s consent before psychological research is conducted on them, Facebook didn’t ask for explicit permission from those it selected for the experiment. It argued that its 1.28 billion monthly users gave blanket consent to the company’s research as a condition of using the service.\n",
    "\n",
    "<br><br><br><br><br><br>\n",
    "\n",
    "![rec](images/rec.png)\n",
    "[source](https://spectrum.ieee.org/tech-talk/telecom/internet/women-less-likely-to-be-shown-ads-for-highpaying-jobs)\n",
    "- Fairness in recommendation systems\n",
    "- Experiment: create fake Google profiles, then search for jobs\n",
    "- Only difference was gender\n",
    "> The male profiles were much more likely to be shown ads for a career coaching service for executive positions paying over $200,000. The Google ad network showed this ad to the male users more than 1800 times, but only about 300 times to women.\n",
    "\n",
    "\n",
    "<br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "![pro](images/pro.png)\n",
    "<img src=\"images/housing.png\" width=400>\n",
    "[source](https://www.propublica.org/article/facebook-advertising-discrimination-housing-race-sex-national-origin)\n",
    "- Facebook let you advertise apartment rentals while excluding people based on ethnicity\n",
    "\n",
    "> Last week, ProPublica bought dozens of rental housing ads on Facebook, but asked that they not be shown to certain categories of users, such as African Americans, mothers of high school kids, people interested in wheelchair ramps, Jews, expats from Argentina and Spanish speakers.  \n",
    "All of these groups are protected under the federal Fair Housing Act, which makes it illegal to publish any advertisement “with respect to the sale or rental of a dwelling that indicates any preference, limitation, or discrimination based on race, color, religion, sex, handicap, familial status, or national origin.” Violators can face tens of thousands of dollars in fines.  \n",
    "**Every single ad was approved within minutes.**\n",
    "\n",
    "\n",
    "<br><br><br><br><br><br>\n",
    "\n",
    "Many ethical issues in computer science:\n",
    "\n",
    "- **Privacy**: What data can be collected? shared? with whom?\n",
    "- **Consent**: Scientists are bound by ethical guidelines when conducting research involving humans.\n",
    "- **Fairness**: When algorithms are used to make decisions about people, they must not discriminate based on protected classes of people (e.g., by gender, race/ethnicity, sexual orientation, etc.).\n",
    "\n",
    "**How can we decide if our behavior is ethical?**\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "**[Belmont Report](https://en.wikipedia.org/wiki/Belmont_Report)**\n",
    "- Ethical guidelines published in 1979 for scientific research\n",
    "- Response to notorious [Tuskegee syphilis experiments](https://en.wikipedia.org/wiki/Tuskegee_syphilis_experiment)\n",
    "  - 40 year study by U.S. Public Health Service on population of impoverished African Americans in Alabama\n",
    "  > Researchers knowingly failed to treat patients appropriately after the 1940s validation of penicillin was found as an effective cure for the disease they were studying.\n",
    "  \n",
    "**Three ethical principals outlines in Belmont Report**\n",
    "\n",
    "1. **Respect for persons:** protecting the autonomy of all people and treating them with courtesy and respect and allowing for informed consent.\n",
    "  - Researchers must be truthful and conduct no deception\n",
    "  - Subjects enter into the research voluntarily and with adequate information  \n",
    "<br><br>\n",
    "2. **Beneficence:** The philosophy of \"Do no harm\" while maximizing benefits for the research project and minimizing risks to the research subjects\n",
    "<br><br>\n",
    "3. **Justice:** ensuring reasonable, non-exploitative, and well-considered procedures are administered fairly — the fair distribution of costs and benefits to potential research participants — and equally.\n",
    "\n",
    "Applying the above principals leads to the following requirements:\n",
    "\n",
    "1. **Informed Consent:**  Respect for persons requires that subjects, to the degree that they are capable, be given the opportunity to choose what shall or shall not happen to them. \n",
    "<br><br>\n",
    "2. **Assessment of Risks and Benefits:** We must protect against risk of harm to subjects and also consider loss of the substantial benefits that might be gained from research.\n",
    "  - Are the expected benefits of the research worth the cost?\n",
    "<br><br>  \n",
    "3. **Selection of Subjects:** Potentially beneficial research should not be restricted only to some subjects; nor should only \"undesirable\" persons be selected for risky research.\n",
    "\n",
    "\n",
    "<br><br><br><br>\n",
    "** Institutional Review Board:**\n",
    "- Every university has a panel of faculty that assess a proposed research project by the above criteria\n",
    "- Much of social media research can be deemed \"non human subjects\" research if passively observing public data:\n",
    "  > Research involving collection or study of existing data, documents, records, pathological specimens, or diagnostic specimens: (i) if these sources are publicly available; or (ii) if the information is recorded by the investigator in such a manner that subjects cannot be identified, directly or through identifiers linked to the subjects\n",
    "\n",
    "<br><br><br><br>\n",
    "**Challenges in applying these principals**\n",
    "\n",
    "- Do users know which data is private?\n",
    "![privacy](images/privacy.png)\n",
    "[source](https://www.usnews.com/opinion/articles/2012/12/28/is-facebooks-privacy-policy-too-confusing)\n",
    "> The family photo posted by Zuckerberg showed up on the newsfeed of Vox Media's Callie Schweitzer because they have a mutual friend, but Zuckerberg did not intend for the photo to become public. She said it was \"way uncool\" for Schweitzer to post the private photo to Twitter.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "- How can we ensure anonymity?\n",
    "![aol](images/aol.png)\n",
    "[source](https://techcrunch.com/2006/08/06/aol-proudly-releases-massive-amounts-of-user-search-data/)\n",
    ">  AOL has released very private data about its users without their permission. While the AOL username has been changed to a random ID number, the abilitiy to analyze all searches by a single user will often lead people to easily determine who the user is, and what they are up to. The data includes personal names, addresses, social security numbers and everything else someone might type into a search box.\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "- How can we ensure fairness?\n",
    "![kleinberg](images/kleinberg.png)\n",
    "> Recent discussion in the public sphere about algorithmic classification has involved tension between competing notions of what it means for a probabilistic classification to be fair to different groups. We formalize three fairness conditions that lie at the heart of these debates, and we prove that except in highly constrained special cases, there is no method that can satisfy these three conditions simultaneously. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "Two computing organizations provide ethical guidelines:\n",
    "\n",
    "- Association for Computing Machinery (ACM): <https://ethics.acm.org/code-of-ethics/>\n",
    "- Institute of Electrical and Electronics Engineers (IEEE): <https://www.ieee.org/about/corporate/governance/p7-8.html>\n",
    "\n",
    "<br><br>\n",
    "\n",
    "ACM Guidelines:\n",
    "\n",
    "** 1. GENERAL MORAL IMPERATIVES.**\n",
    "\n",
    "1.1 Contribute to society and human well-being.  \n",
    "1.2 Avoid harm to others.  \n",
    "1.3 Be honest and trustworthy.  \n",
    "1.4 Be fair and take action not to discriminate.  \n",
    "1.5 Honor property rights including copyrights and patent.  \n",
    "1.6 Give proper credit for intellectual property.  \n",
    "1.7 Respect the privacy of others.  \n",
    "1.8 Honor confidentiality.  \n",
    "\n",
    "** 2. MORE SPECIFIC PROFESSIONAL RESPONSIBILITIES. **\n",
    "\n",
    "2.1 Strive to achieve the highest quality, effectiveness and dignity in both the process and products of professional work.  \n",
    "2.2 Acquire and maintain professional competence.  \n",
    "2.3 Know and respect existing laws pertaining to professional work.  \n",
    "2.4 Accept and provide appropriate professional review.  \n",
    "2.5 Give comprehensive and thorough evaluations of computer systems and their impacts, including analysis of possible risks.  \n",
    "2.6 Honor contracts, agreements, and assigned responsibilities.  \n",
    "2.7 Improve public understanding of computing and its consequences.  \n",
    "2.8 Access computing and communication resources only when authorized to do so.  \n",
    "\n",
    "<br><br>\n",
    "\n",
    "** [A Case Study:](https://ethics.acm.org/code-of-ethics/using-the-code/case-dark-ux-patterns/) **\n",
    "> <u>Using the Code: Dark UX Patterns</u>\n",
    "\n",
    "> The change request Stewart received was simple enough: replace the web site’s rounded rectangle buttons with arrows and adjust the color palette to one that mixes red and green text. But when Steward looked at the prototype, he found it confusing. The left arrow suggested that the web site would go back to a previous page or cancel some action; instead, this arrow replaced the button for accepting the company’s default product. The right arrow, on the other hand, upgraded the user to the more expensive category; it also silently added a protection warranty without asking for confirmation. Stewart suggested to his manager that this confusing design would probably trick users into more expensive options that they didn’t want. The response was that these were the changes requested by the client.\n",
    "\n",
    "> Shortly after the updates were released into their production system, Stewart’s team was invited to a celebration. As a result of these changes, revenues at their client had increased significantly over the previous quarter. At the celebration, Stewart overheard some of the client’s managers discussing the small increase for refunds by users who claimed that they didn’t want the protection plan, but there weren’t many. One manager noted several complaints from visually impaired users, who noted that the mixture of red and green text obscured important disclaimers about the product. “So what you’re saying, then, is that the changes worked as planned,” quipped one of the managers.\n",
    "\n",
    "\n",
    "** What parts of ACM guidelines are relevant here? **\n",
    "\n",
    "\n",
    "<br><br><br><br>\n",
    "** Analysis **\n",
    "\n",
    "> Dark user experience (UX) patterns, which are designs that intend to trick users toward unintended (and often more expensive) options, cause harm. They can make users feel duped (Principle 1.2), provide deliberately misleading information (Principle 1.3), or discriminate against those with disabilities (Principle 1.4). Computing professionals have a moral obligation to use their skills to benefit the members of society (Principle 1.1), not to deceive them. Furthermore, the use of dark UX patterns is an affront to the dignity of users, violating Principle 2.1. Consequently, dark UX patterns violate several of the core principles of the Code.\n",
    "\n",
    "> The development and testing infrastructure should provide a more thorough evaluation of changes to their interface (Principle 2.5)\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "**Conclusion**\n",
    "- Think carefully before conducting studies involving human data\n",
    "- Would a reasonable person be upset about how the research was conducted?\n",
    "- Have Institutional Review Board review research proposal\n",
    "- Read through ACM/IEEE guidelines to think about ethical principles important to computing \n",
    "- Get feedback from others working in the area"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
